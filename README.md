# RAG-QA - сервис вопрос-ответ по базе знаний

## Описание проекта

Проект представляет собой инженерный прототип сервиса вопрос-ответ (Q&A),
построенного на архитектуре Retrieval-Augmented Generation (RAG).

Решение демонстрирует построение системы поиска по базе знаний с последующей
генерацией ответов с использованием большой языковой модели (LLM).
Архитектура разделена на независимые компоненты индексации, поиска и генерации,
что позволяет масштабировать и дорабатывать систему под прикладные задачи.

В репозитории представлена публичная демонстрационная версия проекта.

---

## Ключевые возможности

- Очистка, нормализация и чанкинг текстовых данных
- Векторный и гибридный поиск по базе знаний (FAISS, BM25)
- Генерация ответов с использованием LLM поверх retrieval
- REST API для взаимодействия с системой (FastAPI)
- Контейнеризация сервисов (Docker)

---

## Архитектура решения

Система построена по модульному принципу и включает следующие компоненты:

- сервис индексации и подготовки данных
- векторную базу данных FAISS
- сервис поиска и формирования контекста
- сервис генерации ответов на базе LLM
- API-слой для обработки пользовательских запросов

Архитектура позволяет независимо масштабировать индексацию, поиск и генерацию,
а также адаптировать решение под различные сценарии использования.

---

## Технологический стек

- Язык программирования: Python
- API: FastAPI
- Поиск и retrieval: FAISS, BM25
- Эмбеддинги: `intfloat/multilingual-e5-base`
- LLM: Mistral-7B-Instruct
- Контейнеризация: Docker

---

## Статус проекта

Инженерный прототип / демонстрационный проект.

Репозиторий предназначен для демонстрации архитектурных и ML-подходов.
Коммерческие доработки и интеграции в репозиторий не включены.

---

## Примеры использования

Сервис принимает текстовый запрос и возвращает ответ,
сформированный на основе релевантных фрагментов базы знаний.

Примеры запросов и ответы приведены в разделе со скриншотами проекта.
