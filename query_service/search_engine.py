import json
import numpy as np
import torch
from sentence_transformers import SentenceTransformer, util
from pathlib import Path
import sys

class SearchEngine:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –ø–æ —ç–º–±–µ–¥–¥–∏–Ω–≥—É –∑–∞–ø—Ä–æ—Å–∞.
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–∞–Ω–∫–æ–≤ –∏ –∏—Ö ID, –≤–µ–∫—Ç–æ—Ä–∏–∑—É–µ—Ç –∑–∞–ø—Ä–æ—Å –∏ –Ω–∞—Ö–æ–¥–∏—Ç –Ω–∞–∏–±–æ–ª–µ–µ –±–ª–∏–∑–∫–∏–µ —á–∞–Ω–∫–∏.
    """
    def __init__(self,
                 model_name: str = "intfloat/multilingual-e5-base",
                 embeddings_path: str = "vector_db/chunk_embeddings.npy",
                 ids_path: str = "vector_db/chunk_ids.json",
                 texts_path: str = "data/cleaned_text_chunks.json",
                 normalize_embeddings: bool = True):

        print("–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...")
        self.model = SentenceTransformer(model_name)

        print("–ó–∞–≥—Ä—É–∂–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏...")
        self.embeddings = np.load(embeddings_path)
        if isinstance(self.embeddings, np.ndarray):
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            self.embeddings = torch.tensor(self.embeddings, device=device)
        else:
            self.embeddings = self.embeddings.to(device)

        print("–ó–∞–≥—Ä—É–∂–∞–µ–º ID...")
        with open(ids_path, encoding="utf-8") as f:
            self.ids = json.load(f)

        print("–ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—Å—Ç—ã...")
        with open(texts_path, encoding="utf-8") as f:
            chunks = json.load(f)
            self.id2text = {chunk["id"]: chunk["text"] for chunk in chunks}

        if len(self.ids) != len(self.embeddings):
            raise ValueError("–ß–∏—Å–ª–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —á–∏—Å–ª–æ–º ID")

        self.normalize_embeddings = normalize_embeddings
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.embeddings)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.")

    def search(self, query: str, top_k: int = 5):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–∏—Ö —á–∞–Ω–∫–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç top_k –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö ID, —Ç–µ–∫—Å—Ç—ã –∏ –æ—Ü–µ–Ω–∫–∏ –±–ª–∏–∑–æ—Å—Ç–∏.
        """
        query_input = f"query: {query}"
        query_embedding = self.model.encode(
            query_input,
            convert_to_tensor=True,
            normalize_embeddings=self.normalize_embeddings,
            device='cuda' if torch.cuda.is_available() else 'cpu'
        )

        # üî• –ü–µ—Ä–µ–Ω–æ—Å–∏–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–∞ —Ç–æ—Ç –∂–µ –¥–µ–≤–∞–π—Å
        device = query_embedding.device
        embeddings = self.embeddings.to(device)

        scores = util.cos_sim(query_embedding, embeddings)[0]
        top_results = torch.topk(scores, k=top_k)

        results = []
        for score, idx in zip(top_results.values, top_results.indices):
            chunk_id = self.ids[idx]
            chunk_text = self.id2text.get(chunk_id, "<—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω>")
            results.append({
                "id": chunk_id,
                "score": float(score),
                "text": chunk_text
            })

        return results


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("‚ö†Ô∏è –£–∫–∞–∂–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ. –ü—Ä–∏–º–µ—Ä:\npython search_engine.py \"—á—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\"")
        sys.exit(1)

    query = " ".join(sys.argv[1:])

    engine = SearchEngine()
    results = engine.search(query)

    print("\n‚ñ∂Ô∏è –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞:")
    for res in results:
        print(f"\nüîπ ID: {res['id']} | Score: {res['score']:.3f}")
        print(f"–¢–µ–∫—Å—Ç: {res['text'][:500]}{'...' if len(res['text']) > 500 else ''}")

